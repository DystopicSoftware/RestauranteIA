# üçî RestauranteIA - Sistema de Gesti√≥n Inteligente

![Python 3.10.19](https://img.shields.io/badge/Python-3.10.19-blue.svg)
![Status](https://img.shields.io/badge/Status-Migrado%20de%20Colab-green.svg)

Sistema de gesti√≥n de inventarios y ventas para un restaurante, potenciado con Inteligencia Artificial (LangChain + Ollama Llama3) y una arquitectura modular en Python.

Este proyecto fue originalmente prototipado en **Google Colab** y refactorizado para ejecutarse en un entorno local robusto.

## ‚ö†Ô∏è Importante: Compatibilidad de Versiones

Debido a la migraci√≥n desde un entorno de Colab y a la r√°pida evoluci√≥n de las librer√≠as de IA (LangChain, Ollama), **es estrictamente necesario utilizar Python 3.10.19**.

Versiones m√°s recientes (3.11/3.12) o m√°s antiguas pueden generar conflictos con dependencias espec√≠ficas o m√©todos deprecados utilizados en el flujo l√≥gico del agente.

Se recomienda encarecidamente el uso de **Conda** para gestionar este entorno aislado.

## üöÄ Caracter√≠sticas

- **Asistente Virtual H√≠brido:** Dos modos de operaci√≥n (Administrador y Cliente) usando `ChatOllama`.
- **Gesti√≥n de Inventario:** Control de stock, ingredientes y recetas din√°micas.
- **An√°lisis de Datos:** KPIs, reportes de ventas y generaci√≥n de gr√°ficos autom√°ticos con `Matplotlib`.
- **Persistencia:** Base de datos SQLite local (`restaurante.db`) con actualizaci√≥n autom√°tica.
- **Arquitectura Modular:** C√≥digo organizado en capas (`Data`, `Utils`, `Funciones`, `Tools`, `Agents`) para f√°cil mantenimiento.

## üõ†Ô∏è Instalaci√≥n y Configuraci√≥n

Sigue estos pasos para replicar el entorno de desarrollo exacto:

### 1. Clonar el repositorio

git clone https://github.com/TU_USUARIO/RestauranteIA.git
cd RestauranteIA

### 2. Crear Entorno Virtual con Conda (Recomendado)
Para asegurar la compatibilidad mencionada (Python 3.10.19):

# Crear el entorno con la versi√≥n espec√≠fica
conda create -n restaurante python=3.10.19

# Activar el entorno
conda activate restaurante

### 3. Instalar Dependencias
Una vez activo el entorno, instala las librer√≠as necesarias:

pip install -r requirements.txt

### 4. Configurar Ollama
Este proyecto utiliza Ollama ejecut√°ndose localmente.
Descarga e instala Ollama.
Descarga el modelo llama3 (o el que tengas configurado en config/settings.py):

ollama pull llama3

### 5. Ejecuci√≥n
python app.py

# üèóÔ∏è Estructura del Proyecto
/agents: Configuraci√≥n de los agentes de LangChain (Admin/Cliente).


/config: Configuraciones generales y conexi√≥n con el LLM.


/data: Datos iniciales (seeding) de productos e inventario.


/database: Gesti√≥n de conexi√≥n y persistencia con SQLite.


/funciones: L√≥gica de negocio pura (C√°lculo de KPIs, operaciones de inventario).


/tools: Herramientas (Tools) que conectan las funciones con la IA.


/utils: Utilidades de procesamiento de texto y fuzzy matching.


üìÑ Notas de Migraci√≥n


Si vienes del notebook original de Colab, notar√°s que las celdas monol√≠ticas se han separado en m√≥dulos .py espec√≠ficos. Esto facilita la depuraci√≥n y permite que la aplicaci√≥n crezca sin volverse inmanejable.

Hecho con üçî y Python.
